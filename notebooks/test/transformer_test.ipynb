{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349ca076",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = '../../logs/project/run_1/config.json'\n",
    "MODEL_PATH = \"../../logs/project/run_1/best.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f48092f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'engine': 'engine', 'early_stopping_patience': 5, 'label_smoothing': 0.0, 'batch_size': 32, 'val_freq': 1, 'epochs': 50, 'num_workers': 4, 'accum_iter': 1, 'mixed_precision': 'no', 'lr': 0.0003, 'weight_decay': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "\n",
    "with open(CONFIG) as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, dictionary):\n",
    "        for k, v in dictionary.items():\n",
    "            if isinstance(v, dict):\n",
    "                setattr(self, k, Config(v))\n",
    "            else:\n",
    "                setattr(self, k, v)\n",
    "\n",
    "cfg = Config(cfg)\n",
    "cfg.data.root = os.path.join('..', '..', 'data')\n",
    "print(cfg.training.sampling_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataset import SpeechCommandsDataset, get_loader\n",
    "\n",
    "train_dataset = SpeechCommandsDataset(\n",
    "    root_dir=cfg.data.root,\n",
    "    cfg=cfg,\n",
    "    mode='training'\n",
    ")\n",
    "\n",
    "test_dataset = SpeechCommandsDataset(\n",
    "    root_dir=cfg.data.root,\n",
    "    cfg=cfg,\n",
    "    mode='testing'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b869ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from modeling.model import build_model\n",
    "\n",
    "model = build_model(cfg, test_dataset.num_classes)\n",
    "\n",
    "state_dict = torch.load(MODEL_PATH, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95827678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_display_wrong_predictions(model, test_dataset, n=5):\n",
    "    model.eval() \n",
    "    \n",
    "    indices = list(range(len(test_dataset)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    wrong_predictions = []\n",
    "    \n",
    "    for idx in indices:\n",
    "        data, true_label = test_dataset[idx]\n",
    "        \n",
    "        data_tensor = torch.tensor(data, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(data_tensor)\n",
    "            predicted_label = torch.argmax(output, dim=1).item()\n",
    "        \n",
    "        if predicted_label != true_label:\n",
    "            wrong_predictions.append((idx, true_label, predicted_label))\n",
    "        \n",
    "        if len(wrong_predictions) >= n:\n",
    "            break\n",
    "    \n",
    "    for idx, true_label, predicted_label in wrong_predictions:\n",
    "        print(f\"Sample Index: {idx}\")\n",
    "        print(f\"True Label: {list(test_dataset.label_mapping.keys())[true_label]}, Predicted Label: {list(test_dataset.label_mapping.keys())[predicted_label]}\")\n",
    "        \n",
    "        waveform, _ = test_dataset[idx]\n",
    "        display(Audio(waveform, rate=cfg.data.sample_rate))\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d089f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_display_wrong_predictions(model, test_dataset, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_and_plot_confusion_matrix(model, test_dataset):\n",
    "    model.eval()\n",
    "    \n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    for idx in range(len(test_dataset)):\n",
    "        data, true_label = test_dataset[idx]\n",
    "        data_tensor = torch.tensor(data, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(data_tensor)\n",
    "            predicted_label = torch.argmax(output, dim=1).item()\n",
    "        \n",
    "        true_labels.append(true_label)\n",
    "        predicted_labels.append(predicted_label)\n",
    "    \n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(test_dataset.label_mapping.keys()))\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "evaluate_and_plot_confusion_matrix(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af4ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "data, true_label = test_dataset[10]\n",
    "print(\"True label:\", true_label)\n",
    "# During evaluation, after getting model outputs\n",
    "outputs = model(torch.tensor(data, dtype=torch.float32).unsqueeze(0))  # Shape: [B, num_classes]\n",
    "\n",
    "# Print raw logits\n",
    "print(\"Logits:\", outputs[0].detach().cpu().numpy())\n",
    "\n",
    "# Convert to probabilities\n",
    "probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "# Print softmax probabilities for the first sample in the batch\n",
    "print(\"Probabilities:\", probs[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0391801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "def train_on_small_subset(model, dataset, cfg, num_samples=10, num_epochs=20):\n",
    "    # Create a small subset of the dataset\n",
    "    subset_indices = list(range(num_samples))\n",
    "    small_subset = Subset(dataset, subset_indices)\n",
    "    dataloader = DataLoader(small_subset, batch_size=cfg.training.batch_size, shuffle=True)\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.training.lr)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for data, label in dataloader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, label)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Print loss for the epoch\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(dataloader):.4f}\")\n",
    "    \n",
    "    print(\"Training on small subset complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891fe70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(cfg)\n",
    "model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "train_on_small_subset(model, train_dataset, cfg, num_samples=10000, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b742a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "data, true_label = test_dataset[10]\n",
    "print(\"True label:\", true_label)\n",
    "outputs = model(torch.tensor(data, dtype=torch.float32).unsqueeze(0).to(device))  # Shape: [B, num_classes]\n",
    "\n",
    "print(\"Logits:\", outputs[0].detach().cpu().numpy())\n",
    "\n",
    "probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "print(\"Probabilities:\", f\"{probs[0].detach().cpu().numpy().round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db25e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "evaluate_and_plot_confusion_matrix(model, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
