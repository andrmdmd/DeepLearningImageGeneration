{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349ca076",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = '../../logs/project/run_25/config.json'\n",
    "MODEL_PATH = \"../../logs/project/run_25/best.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f48092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "\n",
    "with open(CONFIG) as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, dictionary):\n",
    "        for k, v in dictionary.items():\n",
    "            if isinstance(v, dict):\n",
    "                setattr(self, k, Config(v))\n",
    "            else:\n",
    "                setattr(self, k, v)\n",
    "\n",
    "cfg = Config(cfg)\n",
    "cfg.data.root = os.path.join('..', '..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ccd5949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance in training data:\n",
      "  no: 1853\n",
      "  go: 1861\n",
      "  on: 1864\n",
      "  right: 1852\n",
      "  stop: 1885\n",
      "  off: 1839\n",
      "  up: 1843\n",
      "  yes: 1860\n",
      "  down: 1842\n",
      "  left: 1839\n",
      "  _unknown_: 32550\n",
      "  unknown percentage: 63.71%\n",
      "Class balance in testing data:\n",
      "  down: 253\n",
      "  go: 251\n",
      "  left: 267\n",
      "  no: 252\n",
      "  off: 262\n",
      "  on: 246\n",
      "  right: 259\n",
      "  stop: 249\n",
      "  up: 272\n",
      "  yes: 256\n",
      "  _unknown_: 4268\n",
      "  unknown percentage: 62.44%\n"
     ]
    }
   ],
   "source": [
    "from dataset.dataset import SpeechCommandsDataset, get_loader\n",
    "\n",
    "train_dataset = SpeechCommandsDataset(\n",
    "    root_dir=cfg.data.root,\n",
    "    cfg=cfg,\n",
    "    mode='training'\n",
    ")\n",
    "\n",
    "test_dataset = SpeechCommandsDataset(\n",
    "    root_dir=cfg.data.root,\n",
    "    cfg=cfg,\n",
    "    mode='testing'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b869ad9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mytkom/Documents/DeepLearningSpeechRecognition/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from modeling.model import build_model\n",
    "\n",
    "model = build_model(cfg, test_dataset.num_classes)\n",
    "\n",
    "state_dict = torch.load(MODEL_PATH, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95827678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_display_wrong_predictions(model, test_dataset, n=5):\n",
    "    model.eval() \n",
    "    \n",
    "    indices = list(range(len(test_dataset)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    wrong_predictions = []\n",
    "    \n",
    "    for idx in indices:\n",
    "        data, true_label = test_dataset[idx]\n",
    "        \n",
    "        data_tensor = torch.tensor(data, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(data_tensor)\n",
    "            predicted_label = torch.argmax(output, dim=1).item()\n",
    "        \n",
    "        if predicted_label != true_label:\n",
    "            wrong_predictions.append((idx, true_label, predicted_label))\n",
    "        \n",
    "        if len(wrong_predictions) >= n:\n",
    "            break\n",
    "    \n",
    "    for idx, true_label, predicted_label in wrong_predictions:\n",
    "        print(f\"Sample Index: {idx}\")\n",
    "        print(f\"True Label: {list(test_dataset.label_mapping.keys())[true_label]}, Predicted Label: {list(test_dataset.label_mapping.keys())[predicted_label]}\")\n",
    "        \n",
    "        waveform, _ = test_dataset[idx]\n",
    "        display(Audio(waveform, rate=cfg.data.sample_rate))\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d089f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Index: 5928\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict_keys' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate_and_display_wrong_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m, in \u001b[0;36mevaluate_and_display_wrong_predictions\u001b[0;34m(model, test_dataset, n)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, true_label, predicted_label \u001b[38;5;129;01min\u001b[39;00m wrong_predictions:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample Index: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue Label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_mapping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrue_label\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Predicted Label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_dataset\u001b[38;5;241m.\u001b[39mlabel_mapping\u001b[38;5;241m.\u001b[39mkeys()[predicted_label]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m     waveform, _ \u001b[38;5;241m=\u001b[39m test_dataset[idx]\n\u001b[1;32m     29\u001b[0m     display(Audio(waveform, rate\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msample_rate))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict_keys' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "evaluate_and_display_wrong_predictions(model, test_dataset, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_and_plot_confusion_matrix(model, test_dataset):\n",
    "    model.eval()\n",
    "    \n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    \n",
    "    for idx in range(len(test_dataset)):\n",
    "        data, true_label = test_dataset[idx]\n",
    "        data_tensor = torch.tensor(data, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(data_tensor)\n",
    "            predicted_label = torch.argmax(output, dim=1).item()\n",
    "        \n",
    "        true_labels.append(true_label)\n",
    "        predicted_labels.append(predicted_label)\n",
    "    \n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(test_dataset.label_mapping.keys()))\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "evaluate_and_plot_confusion_matrix(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af4ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "data, true_label = test_dataset[10]\n",
    "print(\"True label:\", true_label)\n",
    "# During evaluation, after getting model outputs\n",
    "outputs = model(torch.tensor(data, dtype=torch.float32).unsqueeze(0))  # Shape: [B, num_classes]\n",
    "\n",
    "# Print raw logits\n",
    "print(\"Logits:\", outputs[0].detach().cpu().numpy())\n",
    "\n",
    "# Convert to probabilities\n",
    "probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "# Print softmax probabilities for the first sample in the batch\n",
    "print(\"Probabilities:\", probs[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0391801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "def train_on_small_subset(model, dataset, cfg, num_samples=10, num_epochs=20):\n",
    "    # Create a small subset of the dataset\n",
    "    subset_indices = list(range(num_samples))\n",
    "    small_subset = Subset(dataset, subset_indices)\n",
    "    dataloader = DataLoader(small_subset, batch_size=cfg.training.batch_size, shuffle=True)\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.training.lr)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for data, label in dataloader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, label)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Print loss for the epoch\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(dataloader):.4f}\")\n",
    "    \n",
    "    print(\"Training on small subset complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891fe70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(cfg)\n",
    "model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "train_on_small_subset(model, train_dataset, cfg, num_samples=10000, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b742a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "data, true_label = test_dataset[10]\n",
    "print(\"True label:\", true_label)\n",
    "outputs = model(torch.tensor(data, dtype=torch.float32).unsqueeze(0).to(device))  # Shape: [B, num_classes]\n",
    "\n",
    "print(\"Logits:\", outputs[0].detach().cpu().numpy())\n",
    "\n",
    "probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "print(\"Probabilities:\", f\"{probs[0].detach().cpu().numpy().round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db25e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "evaluate_and_plot_confusion_matrix(model, test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
