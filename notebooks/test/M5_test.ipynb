{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ca076",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = '../../configuration/multiclass_test/config.json'\n",
    "MODEL_PATH = \"../../logs/multiclass_test/run_8/best.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f48092f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "\n",
    "with open(CONFIG) as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, dictionary):\n",
    "        for k, v in dictionary.items():\n",
    "            if isinstance(v, dict):\n",
    "                setattr(self, k, Config(v))\n",
    "            else:\n",
    "                setattr(self, k, v)\n",
    "\n",
    "cfg = Config(cfg)\n",
    "cfg.data.root = os.path.join('..', '..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataset import SpeechCommandsDataset, get_loader\n",
    "\n",
    "test_dataset = SpeechCommandsDataset(\n",
    "    root_dir=cfg.data.root,\n",
    "    cfg=cfg,\n",
    "    mode='testing'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b869ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from modeling.model import build_model\n",
    "\n",
    "model = build_model(cfg)\n",
    "\n",
    "state_dict = torch.load(MODEL_PATH, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95827678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_display_wrong_predictions(model, test_dataset, n=5):\n",
    "    model.eval() \n",
    "    \n",
    "    indices = list(range(len(test_dataset)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    wrong_predictions = []\n",
    "    \n",
    "    for idx in indices:\n",
    "        data, true_label = test_dataset[idx]\n",
    "        \n",
    "        data_tensor = torch.tensor(data, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(data_tensor)\n",
    "            predicted_label = torch.argmax(output, dim=1).item()\n",
    "        \n",
    "        if predicted_label != true_label:\n",
    "            wrong_predictions.append((idx, true_label, predicted_label))\n",
    "        \n",
    "        if len(wrong_predictions) >= n:\n",
    "            break\n",
    "    \n",
    "    for idx, true_label, predicted_label in wrong_predictions:\n",
    "        print(f\"Sample Index: {idx}\")\n",
    "        print(f\"True Label: {cfg.data.target_commands[true_label]}, Predicted Label: {cfg.data.target_commands[predicted_label]}\")\n",
    "        \n",
    "        waveform, _ = test_dataset[idx]\n",
    "        display(Audio(waveform, rate=cfg.data.sample_rate))\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d089f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_display_wrong_predictions(model, test_dataset, n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
